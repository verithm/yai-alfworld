# VESSL Job Spec — E1: OOD Baseline
# Purpose : Full OOD evaluation of all 5 agents with llama3.1:8b.
#           Establishes the 8B baseline and confirms Reflexion bug is fixed.
# Runtime : ~2–3 h on RTX 3090 (50 games × 5 agents × ~50 steps avg)
# Depends : E0 must pass
# Run with: vessl run create -f vessl/e1-ood-baseline.yaml

name: alfworld-e1-ood-baseline

resources:
  cluster: yonsei-ai-gpu
  preset: gpu-1

image: quay.io/vessl-ai/torch:2.3.1-cuda12.1-r5

env:
  OLLAMA_URL:       "http://localhost:11434"
  ALFWORLD_DATA:    "/data/alfworld"
  MODEL_NAME:       "llama3.1:8b"
  PYTHONUNBUFFERED: "1"

run:
  - command: |
      set -e

      pip install --quiet vessl alfworld textworld rich

      python3 -c "import vessl.storage, os; os.makedirs('/tmp/scripts', exist_ok=True); vessl.storage.download_volume_file('vessl-storage', 'alfworld-scripts', '/tmp/scripts/')"

      mkdir -p /app
      cd /tmp/scripts
      if ls *.zip 1>/dev/null 2>&1; then unzip -o *.zip -d /app/; else cp -r . /app/; fi

      python3 -c "import vessl.storage, os; os.makedirs('/data/alfworld', exist_ok=True); vessl.storage.download_volume_file('vessl-storage', 'alfworld-data', '/data/alfworld/')"

      curl -fsSL https://ollama.com/install.sh | sh
      ollama serve &
      sleep 10
      ollama pull llama3.1:8b

      cd /app
      mkdir -p /app/results
      python scripts/run_baseline.py \
        --agents zero_shot few_shot react reflexion hierarchical \
        --num-games 50 \
        --max-steps 50 \
        --split eval_out_of_distribution \
        --checkpoint /app/results/e1_checkpoint.json \
        --output    /app/results/e1_results.json

      python3 -c "import vessl.storage; vessl.storage.upload_volume_file('/app/results/', 'vessl-storage', 'alfworld-results')"

      echo "=== E1 complete ==="
