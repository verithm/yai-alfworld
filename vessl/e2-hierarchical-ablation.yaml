# VESSL Job Spec — E2: Reflexion + Hierarchical Ablation
# Purpose : Focused comparison of react/reflexion/hierarchical on OOD split.
#           Gate: best agent SR >= 20% required before launching E4.
# Runtime : ~1.5 h on RTX 3090 (50 games × 3 agents)
# Depends : E1 completed
# Run with: vessl run create -f vessl/e2-hierarchical-ablation.yaml

name: alfworld-e2-hierarchical-ablation

resources:
  cluster: yonsei-ai-gpu
  preset: gpu-1

image: quay.io/vessl-ai/torch:2.3.1-cuda12.1-r5

env:
  OLLAMA_URL:       "http://localhost:11434"
  ALFWORLD_DATA:    "/data/alfworld"
  MODEL_NAME:       "llama3.1:8b"
  PYTHONUNBUFFERED: "1"

run:
  - command: |
      set -e

      pip install --quiet vessl alfworld textworld rich

      python3 -c "import vessl.storage, os; os.makedirs('/tmp/scripts', exist_ok=True); vessl.storage.download_volume_file('vessl-storage', 'alfworld-scripts', '/tmp/scripts/')"

      mkdir -p /app
      cd /tmp/scripts
      if ls *.zip 1>/dev/null 2>&1; then unzip -o *.zip -d /app/; else cp -r . /app/; fi

      python3 -c "import vessl.storage, os; os.makedirs('/data/alfworld', exist_ok=True); vessl.storage.download_volume_file('vessl-storage', 'alfworld-data', '/data/alfworld/')"

      curl -fsSL https://ollama.com/install.sh | sh
      ollama serve &
      sleep 10
      ollama pull llama3.1:8b

      cd /app
      mkdir -p /app/results
      python scripts/run_baseline.py \
        --agents react reflexion hierarchical \
        --num-games 50 \
        --max-steps 50 \
        --split eval_out_of_distribution \
        --checkpoint /app/results/e2_checkpoint.json \
        --output    /app/results/e2_results.json

      python3 -c "import vessl.storage; vessl.storage.upload_volume_file('/app/results/', 'vessl-storage', 'alfworld-results')"

      echo "=== E2 complete ==="
